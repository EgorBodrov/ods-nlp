{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6277,"databundleVersionId":323734,"sourceType":"competition"}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Imports","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport re\nimport string\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics import accuracy_score, log_loss, roc_auc_score, f1_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nimport xgboost as xgb\nimport catboost as cb\nfrom scipy.spatial.distance import cosine, euclidean\nfrom scipy.stats import pearsonr, spearmanr\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer, WordNetLemmatizer\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T13:10:57.779782Z","iopub.execute_input":"2025-05-25T13:10:57.780111Z","iopub.status.idle":"2025-05-25T13:10:57.789034Z","shell.execute_reply.started":"2025-05-25T13:10:57.780087Z","shell.execute_reply":"2025-05-25T13:10:57.787868Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"try:\n    nltk.data.find('tokenizers/punkt')\nexcept LookupError:\n    nltk.download('punkt')\ntry:\n    nltk.data.find('corpora/stopwords')\nexcept LookupError:\n    nltk.download('stopwords')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T13:10:58.060640Z","iopub.execute_input":"2025-05-25T13:10:58.060995Z","iopub.status.idle":"2025-05-25T13:10:58.067291Z","shell.execute_reply.started":"2025-05-25T13:10:58.060974Z","shell.execute_reply":"2025-05-25T13:10:58.066210Z"}},"outputs":[],"execution_count":29},{"cell_type":"markdown","source":"## Data reading","metadata":{}},{"cell_type":"code","source":"!unzip /kaggle/input/quora-question-pairs/train.csv.zip","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T09:59:42.196172Z","iopub.execute_input":"2025-05-25T09:59:42.196671Z","iopub.status.idle":"2025-05-25T09:59:43.154391Z","shell.execute_reply.started":"2025-05-25T09:59:42.196642Z","shell.execute_reply":"2025-05-25T09:59:43.153147Z"}},"outputs":[{"name":"stdout","text":"Archive:  /kaggle/input/quora-question-pairs/train.csv.zip\n  inflating: train.csv               \n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"df = pd.read_csv(\"train.csv\")\ndf.sample(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T13:11:01.398736Z","iopub.execute_input":"2025-05-25T13:11:01.399051Z","iopub.status.idle":"2025-05-25T13:11:03.210870Z","shell.execute_reply.started":"2025-05-25T13:11:01.399027Z","shell.execute_reply":"2025-05-25T13:11:03.209944Z"}},"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"            id    qid1    qid2  \\\n288536  288536  409503  409504   \n92228    92228  154436  154437   \n160814  160814  250726  250727   \n394296  394296  527180  527181   \n323251  323251  449197  449198   \n29993    29993   55444   55445   \n250882  250882     574  110220   \n387452  387452  376061  519776   \n119370  119370  193827  193828   \n185109  185109   56388  272537   \n\n                                                question1  \\\n288536  Which one is a better car to buy Fiat Punto pe...   \n92228               Are women attracted to female nudity?   \n160814  What are some good and cheap hotels or hostels...   \n394296  How long could a human survive on just peanut ...   \n323251  What are the pros and cons of buying a propert...   \n29993            Why are fungi considered to be bacteria?   \n250882  If there will be a war between India and Pakis...   \n387452  If we can see distant galaxy using Hubble or s...   \n119370                            How do I break my knee?   \n185109      Which is the largest organ in the human body?   \n\n                                                question2  is_duplicate  \n288536  How does a petrol car engine work using LPG in...             0  \n92228                Are women attracted to testosterone?             0  \n160814  What are some good and cheap hotels or hostels...             0  \n394296        Has peanut butter been banned from schools?             0  \n323251  I have Rs. 9 lacs of black money (was collecti...             0  \n29993                    Are fungi considered a bacteria?             1  \n250882  If war happens between India and Pakistan who ...             1  \n387452  Could the Hubble see Apollo debris if we aimed...             1  \n119370                           How do I break my elbow?             0  \n185109             What is the largest organ of the body?             1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>qid1</th>\n      <th>qid2</th>\n      <th>question1</th>\n      <th>question2</th>\n      <th>is_duplicate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>288536</th>\n      <td>288536</td>\n      <td>409503</td>\n      <td>409504</td>\n      <td>Which one is a better car to buy Fiat Punto pe...</td>\n      <td>How does a petrol car engine work using LPG in...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>92228</th>\n      <td>92228</td>\n      <td>154436</td>\n      <td>154437</td>\n      <td>Are women attracted to female nudity?</td>\n      <td>Are women attracted to testosterone?</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>160814</th>\n      <td>160814</td>\n      <td>250726</td>\n      <td>250727</td>\n      <td>What are some good and cheap hotels or hostels...</td>\n      <td>What are some good and cheap hotels or hostels...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>394296</th>\n      <td>394296</td>\n      <td>527180</td>\n      <td>527181</td>\n      <td>How long could a human survive on just peanut ...</td>\n      <td>Has peanut butter been banned from schools?</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>323251</th>\n      <td>323251</td>\n      <td>449197</td>\n      <td>449198</td>\n      <td>What are the pros and cons of buying a propert...</td>\n      <td>I have Rs. 9 lacs of black money (was collecti...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>29993</th>\n      <td>29993</td>\n      <td>55444</td>\n      <td>55445</td>\n      <td>Why are fungi considered to be bacteria?</td>\n      <td>Are fungi considered a bacteria?</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>250882</th>\n      <td>250882</td>\n      <td>574</td>\n      <td>110220</td>\n      <td>If there will be a war between India and Pakis...</td>\n      <td>If war happens between India and Pakistan who ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>387452</th>\n      <td>387452</td>\n      <td>376061</td>\n      <td>519776</td>\n      <td>If we can see distant galaxy using Hubble or s...</td>\n      <td>Could the Hubble see Apollo debris if we aimed...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>119370</th>\n      <td>119370</td>\n      <td>193827</td>\n      <td>193828</td>\n      <td>How do I break my knee?</td>\n      <td>How do I break my elbow?</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>185109</th>\n      <td>185109</td>\n      <td>56388</td>\n      <td>272537</td>\n      <td>Which is the largest organ in the human body?</td>\n      <td>What is the largest organ of the body?</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":30},{"cell_type":"code","source":"df.dropna(inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T13:11:03.212305Z","iopub.execute_input":"2025-05-25T13:11:03.212630Z","iopub.status.idle":"2025-05-25T13:11:03.334370Z","shell.execute_reply.started":"2025-05-25T13:11:03.212603Z","shell.execute_reply":"2025-05-25T13:11:03.333687Z"}},"outputs":[],"execution_count":31},{"cell_type":"markdown","source":"## Baseline","metadata":{}},{"cell_type":"code","source":"class QuoraBaselineAdvanced:\n    def __init__(self):\n        self.stop_words = set(stopwords.words('english'))\n        self.stemmer = WordNetLemmatizer()\n        self.tfidf_vectorizer = None\n        self.models = {}\n        \n    def preprocess_text(self, text):\n        text = text.lower()\n        text = text.translate(str.maketrans('', '', string.punctuation))\n        text = re.sub(r'\\s+', ' ', text).strip()\n        \n        return text\n\n    def advanced_preprocess(self, text):\n        if pd.isna(text):\n            return \"\"\n        text = self.preprocess_text(text)\n        \n        words = text.split()\n        words = [word for word in words if word not in self.stop_words]\n        words = [self.stemmer.lemmatize(word) for word in words]\n        \n        return ' '.join(words)\n\n    def extract_basic_features(self, q1, q2):\n        features = {}\n\n        features['q1_len'] = len(str(q1))\n        features['q2_len'] = len(str(q2))\n        features['len_diff'] = abs(features['q1_len'] - features['q2_len'])\n        features['len_ratio'] = min(features['q1_len'], features['q2_len']) / max(features['q1_len'], features['q2_len'])\n\n        q1_words = str(q1).split()\n        q2_words = str(q2).split()\n        features['q1_words'] = len(q1_words)\n        features['q2_words'] = len(q2_words)\n        features['words_diff'] = abs(features['q1_words'] - features['q2_words'])\n        \n        common_words = set(q1_words) & set(q2_words)\n        features['common_words'] = len(common_words)\n        features['common_words_ratio'] = len(common_words) / (len(set(q1_words) | set(q2_words)) + 1)\n        \n        union_words = set(q1_words) | set(q2_words)\n        features['jaccard'] = len(common_words) / len(union_words) if union_words else 0\n        \n        return features\n\n    def extract_advanced_features(self, q1, q2):\n        features = self.extract_basic_features(q1, q2)\n        \n        q1_proc = self.advanced_preprocess(q1)\n        q2_proc = self.advanced_preprocess(q2)\n        \n        q1_words_proc = q1_proc.split()\n        q2_words_proc = q2_proc.split()\n        \n        common_words_proc = set(q1_words_proc) & set(q2_words_proc)\n        features['common_words_proc'] = len(common_words_proc)\n        features['jaccard_proc'] = len(common_words_proc) / len(set(q1_words_proc) | set(q2_words_proc)) if (q1_words_proc or q2_words_proc) else 0\n        \n        q1_chars = set(str(q1).lower())\n        q2_chars = set(str(q2).lower())\n        common_chars = q1_chars & q2_chars\n        features['char_jaccard'] = len(common_chars) / len(q1_chars | q2_chars) if (q1_chars or q2_chars) else 0\n\n        features['edit_distance'] = self.levenshtein_distance(str(q1).lower(), str(q2).lower())\n        features['edit_distance_norm'] = features['edit_distance'] / max(len(str(q1)), len(str(q2)))\n        \n        return features\n\n    def levenshtein_distance(self, s1, s2):\n        if len(s1) < len(s2):\n            return self.levenshtein_distance(s2, s1)\n        \n        if len(s2) == 0:\n            return len(s1)\n        \n        previous_row = list(range(len(s2) + 1))\n        for i, c1 in enumerate(s1):\n            current_row = [i + 1]\n            for j, c2 in enumerate(s2):\n                insertions = previous_row[j + 1] + 1\n                deletions = current_row[j] + 1\n                substitutions = previous_row[j] + (c1 != c2)\n                current_row.append(min(insertions, deletions, substitutions))\n            previous_row = current_row\n        \n        return previous_row[-1]\n\n    def prepare_features(self, df):\n        feature_list = []\n        for idx, row in df.iterrows():\n            features = self.extract_advanced_features(row['question1'], row['question2'])\n            feature_list.append(features)\n        \n        feature_df = pd.DataFrame(feature_list)\n        questions = list(df['question1'].fillna('')) + list(df['question2'].fillna(''))\n        \n        if self.tfidf_vectorizer is None:\n            self.tfidf_vectorizer = TfidfVectorizer(\n                max_features=5000,\n                ngram_range=(1, 2),\n                stop_words='english',\n                lowercase=True\n            )\n            self.tfidf_vectorizer.fit(questions)\n        \n        q1_tfidf = self.tfidf_vectorizer.transform(df['question1'].fillna(''))\n        q2_tfidf = self.tfidf_vectorizer.transform(df['question2'].fillna(''))\n        \n        tfidf_cosine = []\n        for i in range(q1_tfidf.shape[0]):\n            cos_sim = 1 - cosine(q1_tfidf[i].toarray().flatten(), q2_tfidf[i].toarray().flatten())\n            tfidf_cosine.append(cos_sim if not np.isnan(cos_sim) else 0)\n        \n        feature_df['tfidf_cosine'] = tfidf_cosine\n        \n        tfidf_stats = []\n        for i in range(q1_tfidf.shape[0]):\n            v1 = q1_tfidf[i].toarray().flatten()\n            v2 = q2_tfidf[i].toarray().flatten()\n            \n            eucl_dist = euclidean(v1, v2)\n            \n            try:\n                pearson_corr = pearsonr(v1, v2)[0]\n                if np.isnan(pearson_corr):\n                    pearson_corr = 0\n            except:\n                pearson_corr = 0\n            \n            tfidf_stats.append({\n                'tfidf_euclidean': eucl_dist,\n                'tfidf_pearson': pearson_corr\n            })\n        \n        tfidf_stats_df = pd.DataFrame(tfidf_stats)\n        feature_df = pd.concat([feature_df, tfidf_stats_df], axis=1)\n        \n        return feature_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T11:11:34.373263Z","iopub.execute_input":"2025-05-25T11:11:34.374222Z","iopub.status.idle":"2025-05-25T11:11:34.402981Z","shell.execute_reply.started":"2025-05-25T11:11:34.374179Z","shell.execute_reply":"2025-05-25T11:11:34.401794Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"def train_baseline_models(X_train, y_train, X_val, y_val):\n    models_config = {\n        'logistic': LogisticRegression(random_state=42, max_iter=1000),\n        'random_forest': RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1),\n        'gradient_boosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n        'xgboost': xgb.XGBClassifier(n_estimators=100, random_state=42, eval_metric='logloss'),\n        'catboost': cb.CatBoostClassifier(iterations=100, random_seed=42, verbose=False)\n    }\n    \n    results = {}\n    \n    for name, model in models_config.items():\n        print(f\"Training {name}...\")\n        \n        model.fit(X_train, y_train)\n        \n        train_pred = model.predict_proba(X_train)[:, 1]\n        val_pred = model.predict_proba(X_val)[:, 1]\n        val_pred_binary = model.predict(X_val)\n        \n        train_logloss = log_loss(y_train, train_pred)\n        val_logloss = log_loss(y_val, val_pred)\n        val_accuracy = accuracy_score(y_val, val_pred_binary)\n        val_auc = roc_auc_score(y_val, val_pred)\n        val_f1 = f1_score(y_val, val_pred_binary)\n        \n        results[name] = {\n            'model': model,\n            'train_logloss': train_logloss,\n            'val_logloss': val_logloss,\n            'val_accuracy': val_accuracy,\n            'val_auc': val_auc,\n            'val_f1': val_f1,\n            'val_predictions': val_pred\n        }\n        \n        print(f\"{name} - Val LogLoss: {val_logloss:.4f}, Val AUC: {val_auc:.4f}, Val Accuracy: {val_accuracy:.4f}\")\n    \n    return results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T10:05:49.845000Z","iopub.execute_input":"2025-05-25T10:05:49.845793Z","iopub.status.idle":"2025-05-25T10:05:49.855184Z","shell.execute_reply.started":"2025-05-25T10:05:49.845755Z","shell.execute_reply":"2025-05-25T10:05:49.854072Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"def create_ensemble(predictions_dict, y_val, method='average'):\n        print(f\"Создание ансамбля методом {method}...\")\n        \n        if method == 'average':\n            ensemble_pred = np.mean([pred for pred in predictions_dict.values()], axis=0)\n        \n        elif method == 'weighted':\n            weights = []\n            preds = []\n            for name, pred in predictions_dict.items():\n                auc = roc_auc_score(y_val, pred)\n                weights.append(auc)\n                preds.append(pred)\n            \n            weights = np.array(weights)\n            weights = weights / weights.sum()\n            \n            ensemble_pred = np.average(preds, axis=0, weights=weights)\n        \n        elif method == 'stacking':\n            stacking_features = np.column_stack(list(predictions_dict.values()))\n            stacking_model = LogisticRegression(random_state=42)\n            \n            kf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n            stacking_pred = np.zeros(len(y_val))\n            \n            for train_idx, val_idx in kf.split(stacking_features, y_val):\n                stacking_model.fit(stacking_features[train_idx], y_val.iloc[train_idx])\n                stacking_pred[val_idx] = stacking_model.predict_proba(stacking_features[val_idx])[:, 1]\n            \n            ensemble_pred = stacking_pred\n        \n        ensemble_logloss = log_loss(y_val, ensemble_pred)\n        ensemble_auc = roc_auc_score(y_val, ensemble_pred)\n        ensemble_accuracy = accuracy_score(y_val, ensemble_pred > 0.5)\n        ensemble_f1 = f1_score(y_val, ensemble_pred > 0.5)\n        \n        print(f\"Ensemble - LogLoss: {ensemble_logloss:.4f}, AUC: {ensemble_auc:.4f}, Accuracy: {ensemble_accuracy:.4f}\")\n        \n        return ensemble_pred, {\n            'logloss': ensemble_logloss,\n            'auc': ensemble_auc,\n            'accuracy': ensemble_accuracy,\n            'f1': ensemble_f1\n        }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T13:13:03.103355Z","iopub.execute_input":"2025-05-25T13:13:03.104484Z","iopub.status.idle":"2025-05-25T13:13:03.114772Z","shell.execute_reply.started":"2025-05-25T13:13:03.104444Z","shell.execute_reply":"2025-05-25T13:13:03.113697Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"X = df[['question1', 'question2']]\ny = df['is_duplicate']\nX_train, X_val, y_train, y_val = train_test_split(\n    X, y, test_size=0.15, random_state=42, stratify=y\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T13:13:07.031349Z","iopub.execute_input":"2025-05-25T13:13:07.031775Z","iopub.status.idle":"2025-05-25T13:13:07.404425Z","shell.execute_reply.started":"2025-05-25T13:13:07.031749Z","shell.execute_reply":"2025-05-25T13:13:07.403444Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"baseline = QuoraBaselineAdvanced()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T13:13:08.508139Z","iopub.execute_input":"2025-05-25T13:13:08.508443Z","iopub.status.idle":"2025-05-25T13:13:09.371219Z","shell.execute_reply.started":"2025-05-25T13:13:08.508422Z","shell.execute_reply":"2025-05-25T13:13:09.369959Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"print(\"features preparation\")\ntrain_features = baseline.prepare_features(X_train)\nval_features = baseline.prepare_features(X_val)\n\nprint(\"Training models\")\nresults = train_baseline_models(train_features, y_train, val_features, y_val)\npredictions = {name: result['val_predictions'] for name, result in results.items()}\n\nbest_model_name = min(results.keys(), key=lambda x: results[x]['val_logloss'])\nprint(f\"\\n=== RESULTS ===\")\nprint(f\"Best model: {best_model_name}\")\n\ndata = {\n    'models': results,\n    'best_model': best_model_name,\n    'train_features': train_features,\n    'val_features': val_features\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T13:13:42.637320Z","iopub.execute_input":"2025-05-25T13:13:42.638158Z","iopub.status.idle":"2025-05-25T13:34:43.108027Z","shell.execute_reply.started":"2025-05-25T13:13:42.638126Z","shell.execute_reply":"2025-05-25T13:34:43.106620Z"}},"outputs":[{"name":"stdout","text":"features preparation\nTraining models\nTraining logistic...\nlogistic - Val LogLoss: 0.5371, Val AUC: 0.7693, Val Accuracy: 0.6861\nTraining random_forest...\nrandom_forest - Val LogLoss: 0.4582, Val AUC: 0.8408, Val Accuracy: 0.7494\nTraining gradient_boosting...\ngradient_boosting - Val LogLoss: 0.4701, Val AUC: 0.8257, Val Accuracy: 0.7379\nTraining xgboost...\nxgboost - Val LogLoss: 0.4505, Val AUC: 0.8405, Val Accuracy: 0.7519\nTraining catboost...\ncatboost - Val LogLoss: 0.4538, Val AUC: 0.8380, Val Accuracy: 0.7493\n\n=== RESULTS ===\nBest model: xgboost\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"ensemble_results = {}\nfor method in ['average', 'weighted', 'stacking']:\n    ens_pred, ens_metrics = create_ensemble(predictions, y_val, method)\n    ensemble_results[method] = {'predictions': ens_pred, 'metrics': ens_metrics}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T13:34:43.109549Z","iopub.execute_input":"2025-05-25T13:34:43.109833Z","iopub.status.idle":"2025-05-25T13:34:44.240135Z","shell.execute_reply.started":"2025-05-25T13:34:43.109809Z","shell.execute_reply":"2025-05-25T13:34:44.239022Z"}},"outputs":[{"name":"stdout","text":"Создание ансамбля методом average...\nEnsemble - LogLoss: 0.4582, AUC: 0.8407, Accuracy: 0.7518\nСоздание ансамбля методом weighted...\nEnsemble - LogLoss: 0.4575, AUC: 0.8410, Accuracy: 0.7519\nСоздание ансамбля методом stacking...\nEnsemble - LogLoss: 0.4560, AUC: 0.8458, Accuracy: 0.7559\n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"best_ensemble_name = min(ensemble_results.keys(), key=lambda x: ensemble_results[x]['metrics']['logloss'])\nbest_ensemble_name","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T13:34:44.242610Z","iopub.execute_input":"2025-05-25T13:34:44.242908Z","iopub.status.idle":"2025-05-25T13:34:44.254148Z","shell.execute_reply.started":"2025-05-25T13:34:44.242886Z","shell.execute_reply":"2025-05-25T13:34:44.253011Z"}},"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"'stacking'"},"metadata":{}}],"execution_count":38},{"cell_type":"markdown","source":"## Submission","metadata":{}},{"cell_type":"code","source":"test = pd.read_csv(\"/kaggle/input/quora-question-pairs/test.csv\")\ntest.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T10:46:02.528410Z","iopub.execute_input":"2025-05-25T10:46:02.529260Z","iopub.status.idle":"2025-05-25T10:46:13.037248Z","shell.execute_reply.started":"2025-05-25T10:46:02.529225Z","shell.execute_reply":"2025-05-25T10:46:13.036340Z"}},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"(2345796, 3)"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"# test_preprocessed = baseline.prepare_features(test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T11:24:00.689773Z","iopub.execute_input":"2025-05-25T11:24:00.690104Z","iopub.status.idle":"2025-05-25T12:57:14.827346Z","shell.execute_reply.started":"2025-05-25T11:24:00.690079Z","shell.execute_reply":"2025-05-25T12:57:14.826289Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"test_preprocessed = pd.read_csv(\"preprocessed.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T13:55:18.137803Z","iopub.execute_input":"2025-05-25T13:55:18.138144Z","iopub.status.idle":"2025-05-25T13:55:24.916911Z","shell.execute_reply.started":"2025-05-25T13:55:18.138120Z","shell.execute_reply":"2025-05-25T13:55:24.916140Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"# test_preprocessed.to_csv(\"preprocessed.csv\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T13:08:34.262299Z","iopub.execute_input":"2025-05-25T13:08:34.263995Z","iopub.status.idle":"2025-05-25T13:09:13.380241Z","shell.execute_reply.started":"2025-05-25T13:08:34.263918Z","shell.execute_reply":"2025-05-25T13:09:13.379260Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"predictions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T13:59:54.182978Z","iopub.execute_input":"2025-05-25T13:59:54.183302Z","iopub.status.idle":"2025-05-25T13:59:54.192298Z","shell.execute_reply.started":"2025-05-25T13:59:54.183280Z","shell.execute_reply":"2025-05-25T13:59:54.191303Z"}},"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"{'logistic': array([0.27471076, 0.66958216, 0.6613475 , ..., 0.65240735, 0.68572857,\n        0.40649905]),\n 'random_forest': array([0.52, 0.64, 0.78, ..., 0.71, 0.67, 0.57]),\n 'gradient_boosting': array([0.30958459, 0.45555244, 0.71000844, ..., 0.66781109, 0.63860876,\n        0.48394027]),\n 'xgboost': array([0.3557791, 0.6136866, 0.6896051, ..., 0.8363831, 0.6733017,\n        0.5013521], dtype=float32),\n 'catboost': array([0.21536092, 0.57247852, 0.74645389, ..., 0.84655037, 0.60469532,\n        0.52922467])}"},"metadata":{}}],"execution_count":42},{"cell_type":"code","source":"stacking_features = np.column_stack(list(predictions.values()))\nstacking_model = LogisticRegression(random_state=42)\n\nkf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\nstacking_pred = np.zeros(len(y_val))\n\nfor train_idx, val_idx in kf.split(stacking_features, y_val):\n    stacking_model.fit(stacking_features[train_idx], y_val.iloc[train_idx])\n    stacking_pred[val_idx] = stacking_model.predict_proba(stacking_features[val_idx])[:, 1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T14:03:51.605412Z","iopub.execute_input":"2025-05-25T14:03:51.606567Z","iopub.status.idle":"2025-05-25T14:03:52.392574Z","shell.execute_reply.started":"2025-05-25T14:03:51.606489Z","shell.execute_reply":"2025-05-25T14:03:52.391597Z"}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"stacking_model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T14:03:57.967829Z","iopub.execute_input":"2025-05-25T14:03:57.968180Z","iopub.status.idle":"2025-05-25T14:03:57.976943Z","shell.execute_reply.started":"2025-05-25T14:03:57.968159Z","shell.execute_reply":"2025-05-25T14:03:57.975795Z"}},"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"LogisticRegression(random_state=42)","text/html":"<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=42)</pre></div></div></div></div></div>"},"metadata":{}}],"execution_count":44},{"cell_type":"code","source":"test_preprocessed.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T14:04:02.866388Z","iopub.execute_input":"2025-05-25T14:04:02.866798Z","iopub.status.idle":"2025-05-25T14:04:02.888489Z","shell.execute_reply.started":"2025-05-25T14:04:02.866766Z","shell.execute_reply":"2025-05-25T14:04:02.887379Z"}},"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"   q1_len  q2_len  len_diff  len_ratio  q1_words  q2_words  words_diff  \\\n0      57      68        11   0.838235        11        14           3   \n1      66      43        23   0.651515        14         7           7   \n2      60      29        31   0.483333        14         6           8   \n3      27      17        10   0.629630         4         3           1   \n4      32      30         2   0.937500         4         6           2   \n\n   common_words  common_words_ratio   jaccard  common_words_proc  \\\n0             2            0.086957  0.090909                  3   \n1             4            0.222222  0.235294                  4   \n2             4            0.266667  0.285714                  3   \n3             0            0.000000  0.000000                  1   \n4             3            0.375000  0.428571                  2   \n\n   jaccard_proc  char_jaccard  edit_distance  edit_distance_norm  \\\n0      0.272727      0.818182             49            0.720588   \n1      0.500000      0.782609             45            0.681818   \n2      0.500000      0.842105             34            0.566667   \n3      0.333333      0.631579             15            0.555556   \n4      0.666667      0.777778             12            0.375000   \n\n   tfidf_cosine  tfidf_euclidean  tfidf_pearson  \n0      0.358764         1.132463       0.358077  \n1      0.635087         0.854298       0.634740  \n2      0.799067         0.633929       0.798939  \n3      0.000000         1.414214      -0.000200  \n4      1.000000         0.000000       1.000000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>q1_len</th>\n      <th>q2_len</th>\n      <th>len_diff</th>\n      <th>len_ratio</th>\n      <th>q1_words</th>\n      <th>q2_words</th>\n      <th>words_diff</th>\n      <th>common_words</th>\n      <th>common_words_ratio</th>\n      <th>jaccard</th>\n      <th>common_words_proc</th>\n      <th>jaccard_proc</th>\n      <th>char_jaccard</th>\n      <th>edit_distance</th>\n      <th>edit_distance_norm</th>\n      <th>tfidf_cosine</th>\n      <th>tfidf_euclidean</th>\n      <th>tfidf_pearson</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>57</td>\n      <td>68</td>\n      <td>11</td>\n      <td>0.838235</td>\n      <td>11</td>\n      <td>14</td>\n      <td>3</td>\n      <td>2</td>\n      <td>0.086957</td>\n      <td>0.090909</td>\n      <td>3</td>\n      <td>0.272727</td>\n      <td>0.818182</td>\n      <td>49</td>\n      <td>0.720588</td>\n      <td>0.358764</td>\n      <td>1.132463</td>\n      <td>0.358077</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>66</td>\n      <td>43</td>\n      <td>23</td>\n      <td>0.651515</td>\n      <td>14</td>\n      <td>7</td>\n      <td>7</td>\n      <td>4</td>\n      <td>0.222222</td>\n      <td>0.235294</td>\n      <td>4</td>\n      <td>0.500000</td>\n      <td>0.782609</td>\n      <td>45</td>\n      <td>0.681818</td>\n      <td>0.635087</td>\n      <td>0.854298</td>\n      <td>0.634740</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>60</td>\n      <td>29</td>\n      <td>31</td>\n      <td>0.483333</td>\n      <td>14</td>\n      <td>6</td>\n      <td>8</td>\n      <td>4</td>\n      <td>0.266667</td>\n      <td>0.285714</td>\n      <td>3</td>\n      <td>0.500000</td>\n      <td>0.842105</td>\n      <td>34</td>\n      <td>0.566667</td>\n      <td>0.799067</td>\n      <td>0.633929</td>\n      <td>0.798939</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>27</td>\n      <td>17</td>\n      <td>10</td>\n      <td>0.629630</td>\n      <td>4</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1</td>\n      <td>0.333333</td>\n      <td>0.631579</td>\n      <td>15</td>\n      <td>0.555556</td>\n      <td>0.000000</td>\n      <td>1.414214</td>\n      <td>-0.000200</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>32</td>\n      <td>30</td>\n      <td>2</td>\n      <td>0.937500</td>\n      <td>4</td>\n      <td>6</td>\n      <td>2</td>\n      <td>3</td>\n      <td>0.375000</td>\n      <td>0.428571</td>\n      <td>2</td>\n      <td>0.666667</td>\n      <td>0.777778</td>\n      <td>12</td>\n      <td>0.375000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":45},{"cell_type":"code","source":"models_ensemble = []\n\nfor model_name, details in data[\"models\"].items():\n    models_ensemble.append(details[\"model\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T14:14:25.924196Z","iopub.execute_input":"2025-05-25T14:14:25.924575Z","iopub.status.idle":"2025-05-25T14:14:25.931492Z","shell.execute_reply.started":"2025-05-25T14:14:25.924550Z","shell.execute_reply":"2025-05-25T14:14:25.929807Z"}},"outputs":[],"execution_count":63},{"cell_type":"code","source":"for indx, x in test_preprocessed.iterrows():\n    predictions = []\n    for estimator in models_ensemble:\n        predictions.append(estimator.predict_proba(x.to_frame().T)[:, 1])\n    predictions = np.array(predictions).reshape(-1, 5)\n    print(predictions.shape)\n    print(predictions)\n\n    result = stacking_model.predict(predictions)\n    print(result)\n    break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T14:12:19.771024Z","iopub.execute_input":"2025-05-25T14:12:19.771366Z","iopub.status.idle":"2025-05-25T14:12:20.035380Z","shell.execute_reply.started":"2025-05-25T14:12:19.771342Z","shell.execute_reply":"2025-05-25T14:12:20.034571Z"}},"outputs":[{"name":"stdout","text":"(1, 5)\n[[0.19741737 0.02       0.08656675 0.04407485 0.06790519]]\n[0]\n","output_type":"stream"}],"execution_count":61},{"cell_type":"code","source":"estimator_predictions = []\n\nfor estimator in models_ensemble:\n    estimator_predictions.append(estimator.predict_proba(test_preprocessed)[:, 1])\n\npredictions = np.array(estimator_predictions).reshape(-1, 5)\nresults = stacking_model.predict(predictions)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T14:14:34.852625Z","iopub.execute_input":"2025-05-25T14:14:34.853981Z","iopub.status.idle":"2025-05-25T14:15:12.115760Z","shell.execute_reply.started":"2025-05-25T14:14:34.853946Z","shell.execute_reply":"2025-05-25T14:15:12.114836Z"}},"outputs":[],"execution_count":65},{"cell_type":"code","source":"len(results)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T14:15:12.117209Z","iopub.execute_input":"2025-05-25T14:15:12.117488Z","iopub.status.idle":"2025-05-25T14:15:12.123355Z","shell.execute_reply.started":"2025-05-25T14:15:12.117455Z","shell.execute_reply":"2025-05-25T14:15:12.122329Z"}},"outputs":[{"execution_count":66,"output_type":"execute_result","data":{"text/plain":"2345796"},"metadata":{}}],"execution_count":66},{"cell_type":"code","source":"pd.DataFrame({\n    \"test_id\": list(range(len(test_preprocessed))),\n    \"is_duplicate\": results.tolist()\n}).to_csv(\"submit_baseline_advanced_ensembles.csv\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T14:15:13.896713Z","iopub.execute_input":"2025-05-25T14:15:13.897089Z","iopub.status.idle":"2025-05-25T14:15:17.150357Z","shell.execute_reply.started":"2025-05-25T14:15:13.897066Z","shell.execute_reply":"2025-05-25T14:15:17.149404Z"}},"outputs":[],"execution_count":67},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}