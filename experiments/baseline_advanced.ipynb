{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6277,"databundleVersionId":323734,"sourceType":"competition"}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Imports","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport re\nimport string\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics import accuracy_score, log_loss, roc_auc_score, f1_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nimport xgboost as xgb\nimport catboost as cb\nfrom scipy.spatial.distance import cosine, euclidean\nfrom scipy.stats import pearsonr, spearmanr\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer, WordNetLemmatizer\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T10:01:27.079985Z","iopub.execute_input":"2025-05-25T10:01:27.080307Z","iopub.status.idle":"2025-05-25T10:01:27.087311Z","shell.execute_reply.started":"2025-05-25T10:01:27.080286Z","shell.execute_reply":"2025-05-25T10:01:27.085957Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"try:\n    nltk.data.find('tokenizers/punkt')\nexcept LookupError:\n    nltk.download('punkt')\ntry:\n    nltk.data.find('corpora/stopwords')\nexcept LookupError:\n    nltk.download('stopwords')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T09:59:30.365899Z","iopub.execute_input":"2025-05-25T09:59:30.366324Z","iopub.status.idle":"2025-05-25T09:59:30.375002Z","shell.execute_reply.started":"2025-05-25T09:59:30.366297Z","shell.execute_reply":"2025-05-25T09:59:30.374061Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"## Data reading","metadata":{}},{"cell_type":"code","source":"!unzip /kaggle/input/quora-question-pairs/train.csv.zip","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T09:59:42.196172Z","iopub.execute_input":"2025-05-25T09:59:42.196671Z","iopub.status.idle":"2025-05-25T09:59:43.154391Z","shell.execute_reply.started":"2025-05-25T09:59:42.196642Z","shell.execute_reply":"2025-05-25T09:59:43.153147Z"}},"outputs":[{"name":"stdout","text":"Archive:  /kaggle/input/quora-question-pairs/train.csv.zip\n  inflating: train.csv               \n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"df = pd.read_csv(\"train.csv\")\ndf.sample(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T09:59:52.796405Z","iopub.execute_input":"2025-05-25T09:59:52.797782Z","iopub.status.idle":"2025-05-25T09:59:54.335577Z","shell.execute_reply.started":"2025-05-25T09:59:52.797739Z","shell.execute_reply":"2025-05-25T09:59:54.334611Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"            id    qid1    qid2  \\\n12494    12494   24069   24070   \n207219  207219  310849  310850   \n362372  362372  492277  261075   \n87668    87668  147608  147609   \n115716  115716    4047  188650   \n17680    17680   33557   33558   \n218414  218414   11233   63215   \n156144  156144  244439  244440   \n255990  255990  370998  334277   \n165644  165644   66488   78416   \n\n                                                question1  \\\n12494   Is Islamic culture friendly with Science Ficti...   \n207219                How difficult is AIATs for medical?   \n362372  As today is 6th of October, 39 years ago at Yo...   \n87668   Is there any calendar app which integrates wit...   \n115716  Has there been scientific evidence that ghosts...   \n17680   How competitive is the hiring process at Chemi...   \n218414  If universe expansion create more gravitationa...   \n156144  Is there any historical movie like The Imitati...   \n255990  I am using the HTC Desire 816 in dual SIM mode...   \n165644  What are the safety precautions on handling sh...   \n\n                                                question2  is_duplicate  \n12494   Can you recommend any good discussion, intervi...             0  \n207219                    How difficult is aiats medical?             1  \n362372                        Who won the Yom Kippur War?             1  \n87668   Mp ananth Kumar hegde has assaulted a doctor a...             0  \n115716  Would there ever be scientific evidence on gho...             1  \n17680   How competitive is the hiring process at First...             0  \n218414  If energy can't be created or destroyed, how c...             1  \n156144  Why did Alan Turing abandon Joan in The Imitat...             0  \n255990  How do I download the Lollipop version for the...             0  \n165644  What are the safety precautions on handling sh...             1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>qid1</th>\n      <th>qid2</th>\n      <th>question1</th>\n      <th>question2</th>\n      <th>is_duplicate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>12494</th>\n      <td>12494</td>\n      <td>24069</td>\n      <td>24070</td>\n      <td>Is Islamic culture friendly with Science Ficti...</td>\n      <td>Can you recommend any good discussion, intervi...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>207219</th>\n      <td>207219</td>\n      <td>310849</td>\n      <td>310850</td>\n      <td>How difficult is AIATs for medical?</td>\n      <td>How difficult is aiats medical?</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>362372</th>\n      <td>362372</td>\n      <td>492277</td>\n      <td>261075</td>\n      <td>As today is 6th of October, 39 years ago at Yo...</td>\n      <td>Who won the Yom Kippur War?</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>87668</th>\n      <td>87668</td>\n      <td>147608</td>\n      <td>147609</td>\n      <td>Is there any calendar app which integrates wit...</td>\n      <td>Mp ananth Kumar hegde has assaulted a doctor a...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>115716</th>\n      <td>115716</td>\n      <td>4047</td>\n      <td>188650</td>\n      <td>Has there been scientific evidence that ghosts...</td>\n      <td>Would there ever be scientific evidence on gho...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>17680</th>\n      <td>17680</td>\n      <td>33557</td>\n      <td>33558</td>\n      <td>How competitive is the hiring process at Chemi...</td>\n      <td>How competitive is the hiring process at First...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>218414</th>\n      <td>218414</td>\n      <td>11233</td>\n      <td>63215</td>\n      <td>If universe expansion create more gravitationa...</td>\n      <td>If energy can't be created or destroyed, how c...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>156144</th>\n      <td>156144</td>\n      <td>244439</td>\n      <td>244440</td>\n      <td>Is there any historical movie like The Imitati...</td>\n      <td>Why did Alan Turing abandon Joan in The Imitat...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>255990</th>\n      <td>255990</td>\n      <td>370998</td>\n      <td>334277</td>\n      <td>I am using the HTC Desire 816 in dual SIM mode...</td>\n      <td>How do I download the Lollipop version for the...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>165644</th>\n      <td>165644</td>\n      <td>66488</td>\n      <td>78416</td>\n      <td>What are the safety precautions on handling sh...</td>\n      <td>What are the safety precautions on handling sh...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"df.dropna(inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T09:59:54.337453Z","iopub.execute_input":"2025-05-25T09:59:54.337917Z","iopub.status.idle":"2025-05-25T09:59:54.453799Z","shell.execute_reply.started":"2025-05-25T09:59:54.337872Z","shell.execute_reply":"2025-05-25T09:59:54.452911Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"## Baseline","metadata":{}},{"cell_type":"code","source":"class QuoraBaselineAdvanced:\n    def __init__(self):\n        self.stop_words = set(stopwords.words('english'))\n        self.stemmer = WordNetLemmatizer()\n        self.tfidf_vectorizer = None\n        self.models = {}\n        \n    def preprocess_text(self, text):\n        text = text.lower()\n        text = text.translate(str.maketrans('', '', string.punctuation))\n        text = re.sub(r'\\s+', ' ', text).strip()\n        \n        return text\n\n    def advanced_preprocess(self, text):\n        if pd.isna(text):\n            return \"\"\n        text = self.preprocess_text(text)\n        \n        words = text.split()\n        words = [word for word in words if word not in self.stop_words]\n        words = [self.stemmer.lemmatize(word) for word in words]\n        \n        return ' '.join(words)\n\n    def extract_basic_features(self, q1, q2):\n        features = {}\n\n        features['q1_len'] = len(str(q1))\n        features['q2_len'] = len(str(q2))\n        features['len_diff'] = abs(features['q1_len'] - features['q2_len'])\n        features['len_ratio'] = min(features['q1_len'], features['q2_len']) / max(features['q1_len'], features['q2_len'])\n\n        q1_words = str(q1).split()\n        q2_words = str(q2).split()\n        features['q1_words'] = len(q1_words)\n        features['q2_words'] = len(q2_words)\n        features['words_diff'] = abs(features['q1_words'] - features['q2_words'])\n        \n        common_words = set(q1_words) & set(q2_words)\n        features['common_words'] = len(common_words)\n        features['common_words_ratio'] = len(common_words) / (len(set(q1_words) | set(q2_words)) + 1)\n        \n        union_words = set(q1_words) | set(q2_words)\n        features['jaccard'] = len(common_words) / len(union_words) if union_words else 0\n        \n        return features\n\n    def extract_advanced_features(self, q1, q2):\n        features = self.extract_basic_features(q1, q2)\n        \n        q1_proc = self.advanced_preprocess(q1)\n        q2_proc = self.advanced_preprocess(q2)\n        \n        q1_words_proc = q1_proc.split()\n        q2_words_proc = q2_proc.split()\n        \n        common_words_proc = set(q1_words_proc) & set(q2_words_proc)\n        features['common_words_proc'] = len(common_words_proc)\n        features['jaccard_proc'] = len(common_words_proc) / len(set(q1_words_proc) | set(q2_words_proc)) if (q1_words_proc or q2_words_proc) else 0\n        \n        q1_chars = set(str(q1).lower())\n        q2_chars = set(str(q2).lower())\n        common_chars = q1_chars & q2_chars\n        features['char_jaccard'] = len(common_chars) / len(q1_chars | q2_chars) if (q1_chars or q2_chars) else 0\n\n        features['edit_distance'] = self.levenshtein_distance(str(q1).lower(), str(q2).lower())\n        features['edit_distance_norm'] = features['edit_distance'] / max(len(str(q1)), len(str(q2)))\n        \n        return features\n\n    def levenshtein_distance(self, s1, s2):\n        if len(s1) < len(s2):\n            return self.levenshtein_distance(s2, s1)\n        \n        if len(s2) == 0:\n            return len(s1)\n        \n        previous_row = list(range(len(s2) + 1))\n        for i, c1 in enumerate(s1):\n            current_row = [i + 1]\n            for j, c2 in enumerate(s2):\n                insertions = previous_row[j + 1] + 1\n                deletions = current_row[j] + 1\n                substitutions = previous_row[j] + (c1 != c2)\n                current_row.append(min(insertions, deletions, substitutions))\n            previous_row = current_row\n        \n        return previous_row[-1]\n\n    def prepare_features(self, df):\n        feature_list = []\n        for idx, row in df.iterrows():\n            features = self.extract_advanced_features(row['question1'], row['question2'])\n            feature_list.append(features)\n        \n        feature_df = pd.DataFrame(feature_list)\n        questions = list(df['question1'].fillna('')) + list(df['question2'].fillna(''))\n        \n        if self.tfidf_vectorizer is None:\n            self.tfidf_vectorizer = TfidfVectorizer(\n                max_features=5000,\n                ngram_range=(1, 2),\n                stop_words='english',\n                lowercase=True\n            )\n            self.tfidf_vectorizer.fit(questions)\n        \n        q1_tfidf = self.tfidf_vectorizer.transform(df['question1'].fillna(''))\n        q2_tfidf = self.tfidf_vectorizer.transform(df['question2'].fillna(''))\n        \n        tfidf_cosine = []\n        for i in range(q1_tfidf.shape[0]):\n            cos_sim = 1 - cosine(q1_tfidf[i].toarray().flatten(), q2_tfidf[i].toarray().flatten())\n            tfidf_cosine.append(cos_sim if not np.isnan(cos_sim) else 0)\n        \n        feature_df['tfidf_cosine'] = tfidf_cosine\n        \n        tfidf_stats = []\n        for i in range(q1_tfidf.shape[0]):\n            v1 = q1_tfidf[i].toarray().flatten()\n            v2 = q2_tfidf[i].toarray().flatten()\n            \n            eucl_dist = euclidean(v1, v2)\n            \n            try:\n                pearson_corr = pearsonr(v1, v2)[0]\n                if np.isnan(pearson_corr):\n                    pearson_corr = 0\n            except:\n                pearson_corr = 0\n            \n            tfidf_stats.append({\n                'tfidf_euclidean': eucl_dist,\n                'tfidf_pearson': pearson_corr\n            })\n        \n        tfidf_stats_df = pd.DataFrame(tfidf_stats)\n        feature_df = pd.concat([feature_df, tfidf_stats_df], axis=1)\n        \n        return feature_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T11:11:34.373263Z","iopub.execute_input":"2025-05-25T11:11:34.374222Z","iopub.status.idle":"2025-05-25T11:11:34.402981Z","shell.execute_reply.started":"2025-05-25T11:11:34.374179Z","shell.execute_reply":"2025-05-25T11:11:34.401794Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"def train_baseline_models(X_train, y_train, X_val, y_val):\n    models_config = {\n        'logistic': LogisticRegression(random_state=42, max_iter=1000),\n        'random_forest': RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1),\n        'gradient_boosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n        'xgboost': xgb.XGBClassifier(n_estimators=100, random_state=42, eval_metric='logloss'),\n        'catboost': cb.CatBoostClassifier(iterations=100, random_seed=42, verbose=False)\n    }\n    \n    results = {}\n    \n    for name, model in models_config.items():\n        print(f\"Training {name}...\")\n        \n        model.fit(X_train, y_train)\n        \n        train_pred = model.predict_proba(X_train)[:, 1]\n        val_pred = model.predict_proba(X_val)[:, 1]\n        val_pred_binary = model.predict(X_val)\n        \n        train_logloss = log_loss(y_train, train_pred)\n        val_logloss = log_loss(y_val, val_pred)\n        val_accuracy = accuracy_score(y_val, val_pred_binary)\n        val_auc = roc_auc_score(y_val, val_pred)\n        val_f1 = f1_score(y_val, val_pred_binary)\n        \n        results[name] = {\n            'model': model,\n            'train_logloss': train_logloss,\n            'val_logloss': val_logloss,\n            'val_accuracy': val_accuracy,\n            'val_auc': val_auc,\n            'val_f1': val_f1,\n            'val_predictions': val_pred\n        }\n        \n        print(f\"{name} - Val LogLoss: {val_logloss:.4f}, Val AUC: {val_auc:.4f}, Val Accuracy: {val_accuracy:.4f}\")\n    \n    return results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T10:05:49.845000Z","iopub.execute_input":"2025-05-25T10:05:49.845793Z","iopub.status.idle":"2025-05-25T10:05:49.855184Z","shell.execute_reply.started":"2025-05-25T10:05:49.845755Z","shell.execute_reply":"2025-05-25T10:05:49.854072Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"X = df[['question1', 'question2']]\ny = df['is_duplicate']\nX_train, X_val, y_train, y_val = train_test_split(\n    X, y, test_size=0.15, random_state=42, stratify=y\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T10:05:54.449099Z","iopub.execute_input":"2025-05-25T10:05:54.449444Z","iopub.status.idle":"2025-05-25T10:05:54.795607Z","shell.execute_reply.started":"2025-05-25T10:05:54.449421Z","shell.execute_reply":"2025-05-25T10:05:54.794569Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"baseline = QuoraBaselineAdvanced()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T11:23:47.534692Z","iopub.execute_input":"2025-05-25T11:23:47.535048Z","iopub.status.idle":"2025-05-25T11:23:47.540881Z","shell.execute_reply.started":"2025-05-25T11:23:47.535023Z","shell.execute_reply":"2025-05-25T11:23:47.539858Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"print(\"features preparation\")\ntrain_features = baseline.prepare_features(X_train)\nval_features = baseline.prepare_features(X_val)\n\nprint(\"Training models\")\nresults = train_baseline_models(train_features, y_train, val_features, y_val)\npredictions = {name: result['val_predictions'] for name, result in results.items()}\n\nbest_model_name = min(results.keys(), key=lambda x: results[x]['val_logloss'])\nprint(f\"\\n=== RESULTS ===\")\nprint(f\"Best model: {best_model_name}\")\n\ndata = {\n    'models': results,\n    'best_model': best_model_name,\n    'train_features': train_features,\n    'val_features': val_features\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T10:06:16.483912Z","iopub.execute_input":"2025-05-25T10:06:16.485190Z","iopub.status.idle":"2025-05-25T10:26:56.116434Z","shell.execute_reply.started":"2025-05-25T10:06:16.485145Z","shell.execute_reply":"2025-05-25T10:26:56.115593Z"}},"outputs":[{"name":"stdout","text":"features preparation\nTraining models\nTraining logistic...\nlogistic - Val LogLoss: 0.5371, Val AUC: 0.7693, Val Accuracy: 0.6861\nTraining random_forest...\nrandom_forest - Val LogLoss: 0.4582, Val AUC: 0.8408, Val Accuracy: 0.7494\nTraining gradient_boosting...\ngradient_boosting - Val LogLoss: 0.4701, Val AUC: 0.8257, Val Accuracy: 0.7379\nTraining xgboost...\nxgboost - Val LogLoss: 0.4505, Val AUC: 0.8405, Val Accuracy: 0.7519\nTraining catboost...\ncatboost - Val LogLoss: 0.4538, Val AUC: 0.8380, Val Accuracy: 0.7493\n\n=== RESULTS ===\nBest model: xgboost\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T10:45:52.615820Z","iopub.execute_input":"2025-05-25T10:45:52.616241Z","iopub.status.idle":"2025-05-25T10:45:52.642364Z","shell.execute_reply.started":"2025-05-25T10:45:52.616213Z","shell.execute_reply":"2025-05-25T10:45:52.641042Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"{'models': {'logistic': {'model': LogisticRegression(max_iter=1000, random_state=42),\n   'train_logloss': 0.5353225952876173,\n   'val_logloss': 0.5371187001266927,\n   'val_accuracy': 0.6860695204801794,\n   'val_auc': 0.7693261442585191,\n   'val_f1': 0.5464335064563778,\n   'val_predictions': array([0.27471076, 0.66958216, 0.6613475 , ..., 0.65240735, 0.68572857,\n          0.40649905])},\n  'random_forest': {'model': RandomForestClassifier(n_jobs=-1, random_state=42),\n   'train_logloss': 0.1256312873012709,\n   'val_logloss': 0.45816879636415403,\n   'val_accuracy': 0.7493569025789856,\n   'val_auc': 0.8407768267549366,\n   'val_f1': 0.6701961465023433,\n   'val_predictions': array([0.52, 0.64, 0.78, ..., 0.71, 0.67, 0.57])},\n  'gradient_boosting': {'model': GradientBoostingClassifier(random_state=42),\n   'train_logloss': 0.46877256298499986,\n   'val_logloss': 0.47006089460433753,\n   'val_accuracy': 0.7379130664204209,\n   'val_auc': 0.8257180115946738,\n   'val_f1': 0.674169741697417,\n   'val_predictions': array([0.30958459, 0.45555244, 0.71000844, ..., 0.66781109, 0.63860876,\n          0.48394027])},\n  'xgboost': {'model': XGBClassifier(base_score=None, booster=None, callbacks=None,\n                 colsample_bylevel=None, colsample_bynode=None,\n                 colsample_bytree=None, device=None, early_stopping_rounds=None,\n                 enable_categorical=False, eval_metric='logloss',\n                 feature_types=None, gamma=None, grow_policy=None,\n                 importance_type=None, interaction_constraints=None,\n                 learning_rate=None, max_bin=None, max_cat_threshold=None,\n                 max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n                 max_leaves=None, min_child_weight=None, missing=nan,\n                 monotone_constraints=None, multi_strategy=None, n_estimators=100,\n                 n_jobs=None, num_parallel_tree=None, random_state=42, ...),\n   'train_logloss': 0.42947442159034266,\n   'val_logloss': 0.45052830115903014,\n   'val_accuracy': 0.7518963129081195,\n   'val_auc': 0.8404802320018238,\n   'val_f1': 0.6848081112786996,\n   'val_predictions': array([0.3557791, 0.6136866, 0.6896051, ..., 0.8363831, 0.6733017,\n          0.5013521], dtype=float32)},\n  'catboost': {'model': <catboost.core.CatBoostClassifier at 0x7ad7657b6850>,\n   'train_logloss': 0.4448381312035607,\n   'val_logloss': 0.45383726605531194,\n   'val_accuracy': 0.749274454191676,\n   'val_auc': 0.838007601478498,\n   'val_f1': 0.6802111594842998,\n   'val_predictions': array([0.21536092, 0.57247852, 0.74645389, ..., 0.84655037, 0.60469532,\n          0.52922467])}},\n 'best_model': 'xgboost',\n 'train_features':         q1_len  q2_len  len_diff  len_ratio  q1_words  q2_words  words_diff  \\\n 0           66      47        19   0.712121        11         7           4   \n 1           40      42         2   0.952381         8         9           1   \n 2           23      27         4   0.851852         4         4           0   \n 3           44      43         1   0.977273         6         6           0   \n 4           30      52        22   0.576923         6        10           4   \n ...        ...     ...       ...        ...       ...       ...         ...   \n 343638      26      40        14   0.650000         5         7           2   \n 343639      31      27         4   0.870968         5         5           0   \n 343640      67      75         8   0.893333        14        14           0   \n 343641      52      82        30   0.634146         8        14           6   \n 343642     176     181         5   0.972376        34        36           2   \n \n         common_words  common_words_ratio   jaccard  common_words_proc  \\\n 0                  5            0.357143  0.384615                  4   \n 1                  5            0.384615  0.416667                  2   \n 2                  2            0.285714  0.333333                  1   \n 3                  5            0.625000  0.714286                  2   \n 4                  4            0.307692  0.333333                  1   \n ...              ...                 ...       ...                ...   \n 343638             4            0.444444  0.500000                  3   \n 343639             2            0.222222  0.250000                  2   \n 343640             5            0.227273  0.238095                  3   \n 343641             4            0.210526  0.222222                  2   \n 343642             7            0.132075  0.134615                  6   \n \n         jaccard_proc  char_jaccard  edit_distance  edit_distance_norm  \\\n 0           0.800000      0.950000             23            0.348485   \n 1           0.333333      0.772727             14            0.333333   \n 2           0.333333      0.722222             16            0.592593   \n 3           0.500000      1.000000              1            0.022727   \n 4           0.166667      0.736842             27            0.519231   \n ...              ...           ...            ...                 ...   \n 343638      0.600000      0.842105             14            0.350000   \n 343639      1.000000      0.937500              9            0.290323   \n 343640      0.272727      0.863636             48            0.640000   \n 343641      0.285714      0.857143             37            0.451220   \n 343642      0.230769      0.774194            141            0.779006   \n \n         tfidf_cosine  tfidf_euclidean  tfidf_pearson  \n 0           0.944423         0.333398       0.944367  \n 1           0.416721         1.080073       0.416131  \n 2           0.000000         0.000000       0.000000  \n 3           0.700336         0.774163       0.700098  \n 4           0.607678         0.885802       0.607489  \n ...              ...              ...            ...  \n 343638      0.732034         0.732074       0.731854  \n 343639      0.563134         0.934737       0.562960  \n 343640      0.520878         0.978900       0.520665  \n 343641      0.282002         1.198330       0.281389  \n 343642      0.373090         1.119741       0.371449  \n \n [343643 rows x 18 columns],\n 'val_features':        q1_len  q2_len  len_diff  len_ratio  q1_words  q2_words  words_diff  \\\n 0          23      19         4   0.826087         7         5           2   \n 1          33      29         4   0.878788         5         4           1   \n 2          37      45         8   0.822222         5         7           2   \n 3          62      46        16   0.741935        12        10           2   \n 4          49      54         5   0.907407        10        10           0   \n ...       ...     ...       ...        ...       ...       ...         ...   \n 60639     124      46        78   0.370968        26        10          16   \n 60640      48      79        31   0.607595        10        14           4   \n 60641      64      54        10   0.843750        11         9           2   \n 60642      49      55         6   0.890909         8        10           2   \n 60643      37      36         1   0.972973         7         8           1   \n \n        common_words  common_words_ratio   jaccard  common_words_proc  \\\n 0                 2            0.181818  0.200000                  2   \n 1                 2            0.250000  0.285714                  2   \n 2                 3            0.300000  0.333333                  2   \n 3                 6            0.375000  0.400000                  3   \n 4                 4            0.235294  0.250000                  3   \n ...             ...                 ...       ...                ...   \n 60639             4            0.137931  0.142857                  3   \n 60640             2            0.086957  0.090909                  0   \n 60641             7            0.500000  0.538462                  4   \n 60642             6            0.461538  0.500000                  4   \n 60643             2            0.142857  0.153846                  2   \n \n        jaccard_proc  char_jaccard  edit_distance  edit_distance_norm  \\\n 0          0.666667      0.600000             14            0.608696   \n 1          0.666667      0.789474              8            0.242424   \n 2          1.000000      0.950000             11            0.244444   \n 3          0.333333      0.750000             26            0.419355   \n 4          0.500000      0.863636             19            0.351852   \n ...             ...           ...            ...                 ...   \n 60639      0.230769      0.760000             96            0.774194   \n 60640      0.000000      0.652174             53            0.670886   \n 60641      0.800000      0.954545             49            0.765625   \n 60642      0.666667      0.947368             15            0.272727   \n 60643      0.333333      0.850000             20            0.540541   \n \n        tfidf_cosine  tfidf_euclidean  tfidf_pearson  \n 0          0.000000         1.000000       0.000000  \n 1          0.908108         0.428701       0.908071  \n 2          1.000000         0.000000       1.000000  \n 3          0.524638         0.975051       0.524153  \n 4          0.683979         0.795011       0.683729  \n ...             ...              ...            ...  \n 60639      0.105928         1.337215       0.105115  \n 60640      0.000000         1.414214      -0.000626  \n 60641      1.000000         0.000000       1.000000  \n 60642      0.807446         0.620570       0.807257  \n 60643      0.685034         0.793683       0.684824  \n \n [60644 rows x 18 columns]}"},"metadata":{}}],"execution_count":14},{"cell_type":"markdown","source":"## Submission","metadata":{}},{"cell_type":"code","source":"test = pd.read_csv(\"/kaggle/input/quora-question-pairs/test.csv\")\ntest.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T10:46:02.528410Z","iopub.execute_input":"2025-05-25T10:46:02.529260Z","iopub.status.idle":"2025-05-25T10:46:13.037248Z","shell.execute_reply.started":"2025-05-25T10:46:02.529225Z","shell.execute_reply":"2025-05-25T10:46:13.036340Z"}},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"(2345796, 3)"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"test_preprocessed = baseline.prepare_features(test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T11:24:00.689773Z","iopub.execute_input":"2025-05-25T11:24:00.690104Z","iopub.status.idle":"2025-05-25T12:57:14.827346Z","shell.execute_reply.started":"2025-05-25T11:24:00.690079Z","shell.execute_reply":"2025-05-25T12:57:14.826289Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"best = data[\"models\"][best_model_name][\"model\"]\nbest","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T12:57:14.829099Z","iopub.execute_input":"2025-05-25T12:57:14.829441Z","iopub.status.idle":"2025-05-25T12:57:14.838586Z","shell.execute_reply.started":"2025-05-25T12:57:14.829412Z","shell.execute_reply":"2025-05-25T12:57:14.837500Z"}},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric='logloss',\n              feature_types=None, gamma=None, grow_policy=None,\n              importance_type=None, interaction_constraints=None,\n              learning_rate=None, max_bin=None, max_cat_threshold=None,\n              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n              max_leaves=None, min_child_weight=None, missing=nan,\n              monotone_constraints=None, multi_strategy=None, n_estimators=100,\n              n_jobs=None, num_parallel_tree=None, random_state=42, ...)","text/html":"<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n              feature_types=None, gamma=None, grow_policy=None,\n              importance_type=None, interaction_constraints=None,\n              learning_rate=None, max_bin=None, max_cat_threshold=None,\n              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n              max_leaves=None, min_child_weight=None, missing=nan,\n              monotone_constraints=None, multi_strategy=None, n_estimators=100,\n              n_jobs=None, num_parallel_tree=None, random_state=42, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n              feature_types=None, gamma=None, grow_policy=None,\n              importance_type=None, interaction_constraints=None,\n              learning_rate=None, max_bin=None, max_cat_threshold=None,\n              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n              max_leaves=None, min_child_weight=None, missing=nan,\n              monotone_constraints=None, multi_strategy=None, n_estimators=100,\n              n_jobs=None, num_parallel_tree=None, random_state=42, ...)</pre></div></div></div></div></div>"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"test_preprocessed.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T12:57:14.839448Z","iopub.execute_input":"2025-05-25T12:57:14.839689Z","iopub.status.idle":"2025-05-25T12:57:14.867945Z","shell.execute_reply.started":"2025-05-25T12:57:14.839670Z","shell.execute_reply":"2025-05-25T12:57:14.867010Z"}},"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"   q1_len  q2_len  len_diff  len_ratio  q1_words  q2_words  words_diff  \\\n0      57      68        11   0.838235        11        14           3   \n1      66      43        23   0.651515        14         7           7   \n2      60      29        31   0.483333        14         6           8   \n3      27      17        10   0.629630         4         3           1   \n4      32      30         2   0.937500         4         6           2   \n\n   common_words  common_words_ratio   jaccard  common_words_proc  \\\n0             2            0.086957  0.090909                  3   \n1             4            0.222222  0.235294                  4   \n2             4            0.266667  0.285714                  3   \n3             0            0.000000  0.000000                  1   \n4             3            0.375000  0.428571                  2   \n\n   jaccard_proc  char_jaccard  edit_distance  edit_distance_norm  \\\n0      0.272727      0.818182             49            0.720588   \n1      0.500000      0.782609             45            0.681818   \n2      0.500000      0.842105             34            0.566667   \n3      0.333333      0.631579             15            0.555556   \n4      0.666667      0.777778             12            0.375000   \n\n   tfidf_cosine  tfidf_euclidean  tfidf_pearson  \n0      0.358764         1.132463       0.358077  \n1      0.635087         0.854298       0.634740  \n2      0.799067         0.633929       0.798939  \n3      0.000000         1.414214      -0.000200  \n4      1.000000         0.000000       1.000000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>q1_len</th>\n      <th>q2_len</th>\n      <th>len_diff</th>\n      <th>len_ratio</th>\n      <th>q1_words</th>\n      <th>q2_words</th>\n      <th>words_diff</th>\n      <th>common_words</th>\n      <th>common_words_ratio</th>\n      <th>jaccard</th>\n      <th>common_words_proc</th>\n      <th>jaccard_proc</th>\n      <th>char_jaccard</th>\n      <th>edit_distance</th>\n      <th>edit_distance_norm</th>\n      <th>tfidf_cosine</th>\n      <th>tfidf_euclidean</th>\n      <th>tfidf_pearson</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>57</td>\n      <td>68</td>\n      <td>11</td>\n      <td>0.838235</td>\n      <td>11</td>\n      <td>14</td>\n      <td>3</td>\n      <td>2</td>\n      <td>0.086957</td>\n      <td>0.090909</td>\n      <td>3</td>\n      <td>0.272727</td>\n      <td>0.818182</td>\n      <td>49</td>\n      <td>0.720588</td>\n      <td>0.358764</td>\n      <td>1.132463</td>\n      <td>0.358077</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>66</td>\n      <td>43</td>\n      <td>23</td>\n      <td>0.651515</td>\n      <td>14</td>\n      <td>7</td>\n      <td>7</td>\n      <td>4</td>\n      <td>0.222222</td>\n      <td>0.235294</td>\n      <td>4</td>\n      <td>0.500000</td>\n      <td>0.782609</td>\n      <td>45</td>\n      <td>0.681818</td>\n      <td>0.635087</td>\n      <td>0.854298</td>\n      <td>0.634740</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>60</td>\n      <td>29</td>\n      <td>31</td>\n      <td>0.483333</td>\n      <td>14</td>\n      <td>6</td>\n      <td>8</td>\n      <td>4</td>\n      <td>0.266667</td>\n      <td>0.285714</td>\n      <td>3</td>\n      <td>0.500000</td>\n      <td>0.842105</td>\n      <td>34</td>\n      <td>0.566667</td>\n      <td>0.799067</td>\n      <td>0.633929</td>\n      <td>0.798939</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>27</td>\n      <td>17</td>\n      <td>10</td>\n      <td>0.629630</td>\n      <td>4</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1</td>\n      <td>0.333333</td>\n      <td>0.631579</td>\n      <td>15</td>\n      <td>0.555556</td>\n      <td>0.000000</td>\n      <td>1.414214</td>\n      <td>-0.000200</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>32</td>\n      <td>30</td>\n      <td>2</td>\n      <td>0.937500</td>\n      <td>4</td>\n      <td>6</td>\n      <td>2</td>\n      <td>3</td>\n      <td>0.375000</td>\n      <td>0.428571</td>\n      <td>2</td>\n      <td>0.666667</td>\n      <td>0.777778</td>\n      <td>12</td>\n      <td>0.375000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"# for indx, x in test_preprocessed.iterrows():\n#     print(x.to_frame().T)\n#     result = best.predict(x.to_frame().T)\n#     print(result)\n#     break\n\n\ntest_results = best.predict(test_preprocessed)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T12:57:14.870038Z","iopub.execute_input":"2025-05-25T12:57:14.870337Z","iopub.status.idle":"2025-05-25T12:57:17.423749Z","shell.execute_reply.started":"2025-05-25T12:57:14.870316Z","shell.execute_reply":"2025-05-25T12:57:17.422712Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"len(test_results)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T12:57:17.424598Z","iopub.execute_input":"2025-05-25T12:57:17.424968Z","iopub.status.idle":"2025-05-25T12:57:17.431023Z","shell.execute_reply.started":"2025-05-25T12:57:17.424946Z","shell.execute_reply":"2025-05-25T12:57:17.430340Z"}},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"2345796"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"test_results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T12:57:17.431925Z","iopub.execute_input":"2025-05-25T12:57:17.432193Z","iopub.status.idle":"2025-05-25T12:57:17.449299Z","shell.execute_reply.started":"2025-05-25T12:57:17.432169Z","shell.execute_reply":"2025-05-25T12:57:17.448375Z"}},"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"array([0, 1, 1, ..., 0, 0, 0])"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"pd.DataFrame({\n    \"test_id\": list(range(len(test_preprocessed))),\n    \"is_duplicate\": test_results.tolist()\n}).to_csv(\"submit_baseline_advanced.csv\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T12:57:17.450277Z","iopub.execute_input":"2025-05-25T12:57:17.450974Z","iopub.status.idle":"2025-05-25T12:57:20.761976Z","shell.execute_reply.started":"2025-05-25T12:57:17.450952Z","shell.execute_reply":"2025-05-25T12:57:20.760561Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}